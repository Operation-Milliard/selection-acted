google:
  oauth_client_path: secrets/client_secret.json
  token_path: secrets/token.json
  sheets:
    grid_spreadsheet_id: gdrive sheet id
    grid_tab: Grille
    responses_spreadsheet_id: 
    responses_tab: Form responses 1
  drive:
    folder_id: gdrive folder id
project:
  name_column: Nom de la structure
  status_column: Status
  # Form fields to include in LLM prompt
  prompt_fields:
    - Nom de la structure
    - Description Du Projet
  # Columns containing files for RAG
  file_columns:
    - Fichiers
output:
  dry_run_report_path: out/dry_run_report.json
  projects_output_dir: out/projects
  llm_output_dir: out/llm
  results_spreadsheet_id: ""
  results_write_mode: skip
  chunk_size_chars: 4000
  chunk_overlap_chars: 400
rag:
  model_name: intfloat/multilingual-e5-small
  top_k: 6
  # Smart chunking options (structure-aware)
  use_smart_chunking: true
  chunk_min_chars: 500
  chunk_max_chars: 2000
  chunk_overlap_sentences: 1

# LLM configuration - works with any OpenAI-compatible API
llm:
  # Base URL (optional, defaults to Mistral API)
  # Examples:
  #   Mistral: https://api.mistral.ai/v1
  #   OpenAI: https://api.openai.com/v1
  #   Ollama: http://localhost:11434/v1
  #   vLLM: http://localhost:8000/v1
  base_url: null
  api_key: ""
  model: mistral-small-latest
  temperature: 0.2
  max_tokens: 512
